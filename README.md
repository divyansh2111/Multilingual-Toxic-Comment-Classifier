# Multilingual-Toxic-Comment-Classifier

It only takes one toxic comment to sour an online discussion. The Conversation AI team, a research initiative founded by Jigsaw and Google, builds technology to protect voices in conversation. A main area of focus is machine learning models that can identify toxicity in online conversations, where toxicity is defined as anything rude, disrespectful or otherwise likely to make someone leave a discussion. If these toxic contributions can be identified, we could have a safer, more collaborative internet. So I tried to contribute towards this model which can handle it in multiple different languages and acquired pretty good accuracy. I would also encourage machine learning enthusiasts to have a go at it as it is still an active contest on Kaggle.
